name: Weekly Interview Scraper Bot

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * 0'  # Every Sunday at midnight UTC

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run main scraper
        env:
          GLASSDOOR_USER: ${{ secrets.GLASSDOOR_USER }}
          GLASSDOOR_PASS: ${{ secrets.GLASSDOOR_PASS }}
        run: |
          python main.py

      - name: Debug directory contents
        run: |
          echo "=== Workspace ==="
          ls -la
          echo "=== Data Folder ==="
          ls -la data || echo "‚ö†Ô∏è data folder not found"

      - name: Commit scraped data
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "bot@users.noreply.github.com"

          if [ -d "data" ]; then
            echo "üìÅ Data directory exists"
            ls -la data || echo "‚ö†Ô∏è No readable files in data"

            git add data/* || echo "‚ö†Ô∏è No files to stage"

            if git diff --cached --quiet; then
              echo "‚ö†Ô∏è No changes to commit"
            else
              git commit -m "ü§ñ Auto-scraped interview data"
              git push
            fi
          else
            echo "üö´ Data directory not found"
          fi
